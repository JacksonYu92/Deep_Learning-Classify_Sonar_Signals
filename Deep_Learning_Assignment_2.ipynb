{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odASNHCXYAru"
   },
   "source": [
    "## Assignment 2: Build a Multilayer Neural Network to Classify Sonar Signals\n",
    "### Student name: Qichun Yu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dtfoa8EsX4Wu"
   },
   "source": [
    "1. Create a new Jupyter notebook and import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "78aNEnLKXrYX"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Import Keras libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lkNdfp-YSd9"
   },
   "source": [
    "2. Use Jupyter notebooks or a text editor to view the sonar.names file in the dropbox folder, which describes the data. Load the sonar.csv file into a Pandas dataframe and print out the first few lines. Provide your own brief description of the data; state what the features are and the datatype associated with each. What is the label and what values can the label take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WvjBj40EX2Ss",
    "outputId": "653fa640-8600-46c8-99f4-ff71bce12890"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: Sonar, Mines vs. Rocks\n",
      "\n",
      "SUMMARY: This is the data set used by Gorman and Sejnowski in their study\n",
      "of the classification of sonar signals using a neural network [1].  The\n",
      "task is to train a network to discriminate between sonar signals bounced\n",
      "off a metal cylinder and those bounced off a roughly cylindrical rock.\n",
      "\n",
      "SOURCE: The data set was contributed to the benchmark collection by Terry\n",
      "Sejnowski, now at the Salk Institute and the University of California at\n",
      "San Deigo.  The data set was developed in collaboration with R. Paul\n",
      "Gorman of Allied-Signal Aerospace Technology Center.\n",
      "\n",
      "MAINTAINER: Scott E. Fahlman\n",
      "\n",
      "PROBLEM DESCRIPTION:\n",
      "\n",
      "The file \"sonar.mines\" contains 111 patterns obtained by bouncing sonar\n",
      "signals off a metal cylinder at various angles and under various\n",
      "conditions.  The file \"sonar.rocks\" contains 97 patterns obtained from\n",
      "rocks under similar conditions.  The transmitted sonar signal is a\n",
      "frequency-modulated chirp, rising in frequency.  The data set contains\n",
      "signals obtained from a variety of different aspect angles, spanning 90\n",
      "degrees for the cylinder and 180 degrees for the rock.\n",
      "\n",
      "Each pattern is a set of 60 numbers in the range 0.0 to 1.0.  Each number\n",
      "represents the energy within a particular frequency band, integrated over\n",
      "a certain period of time.  The integration aperture for higher frequencies\n",
      "occur later in time, since these frequencies are transmitted later during\n",
      "the chirp.\n",
      "\n",
      "The label associated with each record contains the letter \"R\" if the object\n",
      "is a rock and \"M\" if it is a mine (metal cylinder).  The numbers in the\n",
      "labels are in increasing order of aspect angle, but they do not encode the\n",
      "angle directly.\n",
      "\n",
      "METHODOLOGY: \n",
      "\n",
      "This data set can be used in a number of different ways to test learning\n",
      "speed, quality of ultimate learning, ability to generalize, or combinations\n",
      "of these factors.\n",
      "\n",
      "In [1], Gorman and Sejnowski report two series of experiments: an\n",
      "\"aspect-angle independent\" series, in which the whole data set is used\n",
      "without controlling for aspect angle, and an \"aspect-angle dependent\"\n",
      "series in which the training and testing sets were carefully controlled to\n",
      "ensure that each set contained cases from each aspect angle in\n",
      "appropriate proportions.\n",
      "\n",
      "For the aspect-angle independent experiments the combined set of 208 cases\n",
      "is divided randomly into 13 disjoint sets with 16 cases in each.  For each\n",
      "experiment, 12 of these sets are used as training data, while the 13th is\n",
      "reserved for testing.  The experiment is repeated 13 times so that every\n",
      "case appears once as part of a test set.  The reported performance is an\n",
      "average over the entire set of 13 different test sets, each run 10 times.\n",
      "\n",
      "It was observed that this random division of the sample set led to rather\n",
      "uneven performance.  A few of the splits gave poor results, presumably\n",
      "because the test set contains some samples from aspect angles that are\n",
      "under-represented in the corresponding training set.  This motivated Gorman\n",
      "and Sejnowski to devise a different set of experiments in which an attempt\n",
      "was made to balance the training and test sets so that each would have a\n",
      "representative number of samples from all aspect angles.  Since detailed\n",
      "aspect angle information was not present in the data base of samples, the\n",
      "208 samples were first divided into clusters, using a 60-dimensional\n",
      "Euclidian metric; each of these clusters was then divided between the\n",
      "104-member training set and the 104-member test set.  \n",
      "\n",
      "The actual training and testing samples used for the \"aspect angle\n",
      "dependent\" experiments are marked in the data files.  The reported\n",
      "performance is an average over 10 runs with this single division of the\n",
      "data set.\n",
      "\n",
      "A standard back-propagation network was used for all experiments.  The\n",
      "network had 60 inputs and 2 output units, one indicating a cylinder and the\n",
      "other a rock.  Experiments were run with no hidden units (direct\n",
      "connections from each input to each output) and with a single hidden layer\n",
      "with 2, 3, 6, 12, or 24 units.  Each network was trained by 300 epochs over\n",
      "the entire training set.\n",
      "\n",
      "The weight-update formulas used in this study were slightly different from\n",
      "the standard form.  A learning rate of 2.0 and momentum of 0.0 was used.\n",
      "Errors less than 0.2 were treated as zero.  Initial weights were uniform\n",
      "random values in the range -0.3 to +0.3.\n",
      "\n",
      "RESULTS: \n",
      "\n",
      "For the angle independent experiments, Gorman and Sejnowski report the\n",
      "following results for networks with different numbers of hidden units:\n",
      "\n",
      "Hidden\t% Right on\tStd.\t% Right on\tStd.\n",
      "Units\tTraining set\tDev.\tTest Set\tDev.\n",
      "------\t------------\t----\t----------\t----\n",
      "0\t89.4\t\t2.1\t77.1\t\t8.3\n",
      "2\t96.5\t\t0.7\t81.9\t\t6.2\n",
      "3\t98.8\t\t0.4\t82.0\t\t7.3\n",
      "6\t99.7\t\t0.2\t83.5\t\t5.6\n",
      "12\t99.8\t\t0.1\t84.7\t\t5.7\n",
      "24\t99.8\t\t0.1\t84.5\t\t5.7\n",
      "\n",
      "For the angle-dependent experiments Gorman and Sejnowski report the\n",
      "following results:\n",
      "\n",
      "Hidden\t% Right on\tStd.\t% Right on\tStd.\n",
      "Units\tTraining set\tDev.\tTest Set\tDev.\n",
      "------\t------------\t----\t----------\t----\n",
      "0\t79.3\t\t3.4\t73.1\t\t4.8\n",
      "2\t96.2\t\t2.2\t85.7\t\t6.3\n",
      "3\t98.1\t\t1.5\t87.6\t\t3.0\n",
      "6\t99.4\t\t0.9\t89.3\t\t2.4\n",
      "12\t99.8\t\t0.6\t90.4\t\t1.8\n",
      "24     100.0\t\t0.0\t89.2\t\t1.4\n",
      "\n",
      "Not surprisingly, the network's performance on the test set was somewhat\n",
      "better when the aspect angles in the training and test sets were balanced.\n",
      "\n",
      "Gorman and Sejnowski further report that a nearest neighbor classifier on\n",
      "the same data gave an 82.7% probability of correct classification.\n",
      "\n",
      "Three trained human subjects were each tested on 100 signals, chosen at\n",
      "random from the set of 208 returns used to create this data set.  Their\n",
      "responses ranged between 88% and 97% correct.  However, they may have been\n",
      "using information from the raw sonar signal that is not preserved in the\n",
      "processed data sets presented here.\n",
      "\n",
      "REFERENCES: \n",
      "\n",
      "1. Gorman, R. P., and Sejnowski, T. J. (1988).  \"Analysis of Hidden Units\n",
      "in a Layered Network Trained to Classify Sonar Targets\" in Neural Networks,\n",
      "Vol. 1, pp. 75-89.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"sonar.names\") as sonar_names:\n",
    "    print(sonar_names.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "yl4ceI7GYU4v",
    "outputId": "06c2f2c2-17c6-4f55-a13d-eb4141b201b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-5c2dc43c-57b2-4525-865c-77da5e63ebe6\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>attribute_4</th>\n",
       "      <th>attribute_5</th>\n",
       "      <th>attribute_6</th>\n",
       "      <th>attribute_7</th>\n",
       "      <th>attribute_8</th>\n",
       "      <th>attribute_9</th>\n",
       "      <th>attribute_10</th>\n",
       "      <th>...</th>\n",
       "      <th>attribute_52</th>\n",
       "      <th>attribute_53</th>\n",
       "      <th>attribute_54</th>\n",
       "      <th>attribute_55</th>\n",
       "      <th>attribute_56</th>\n",
       "      <th>attribute_57</th>\n",
       "      <th>attribute_58</th>\n",
       "      <th>attribute_59</th>\n",
       "      <th>attribute_60</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c2dc43c-57b2-4525-865c-77da5e63ebe6')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-5c2dc43c-57b2-4525-865c-77da5e63ebe6 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-5c2dc43c-57b2-4525-865c-77da5e63ebe6');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   attribute_1  attribute_2  attribute_3  attribute_4  attribute_5  \\\n",
       "0       0.0200       0.0371       0.0428       0.0207       0.0954   \n",
       "1       0.0453       0.0523       0.0843       0.0689       0.1183   \n",
       "2       0.0262       0.0582       0.1099       0.1083       0.0974   \n",
       "3       0.0100       0.0171       0.0623       0.0205       0.0205   \n",
       "4       0.0762       0.0666       0.0481       0.0394       0.0590   \n",
       "\n",
       "   attribute_6  attribute_7  attribute_8  attribute_9  attribute_10  ...  \\\n",
       "0       0.0986       0.1539       0.1601       0.3109        0.2111  ...   \n",
       "1       0.2583       0.2156       0.3481       0.3337        0.2872  ...   \n",
       "2       0.2280       0.2431       0.3771       0.5598        0.6194  ...   \n",
       "3       0.0368       0.1098       0.1276       0.0598        0.1264  ...   \n",
       "4       0.0649       0.1209       0.2467       0.3564        0.4459  ...   \n",
       "\n",
       "   attribute_52  attribute_53  attribute_54  attribute_55  attribute_56  \\\n",
       "0        0.0027        0.0065        0.0159        0.0072        0.0167   \n",
       "1        0.0084        0.0089        0.0048        0.0094        0.0191   \n",
       "2        0.0232        0.0166        0.0095        0.0180        0.0244   \n",
       "3        0.0121        0.0036        0.0150        0.0085        0.0073   \n",
       "4        0.0031        0.0054        0.0105        0.0110        0.0015   \n",
       "\n",
       "   attribute_57  attribute_58  attribute_59  attribute_60  Class  \n",
       "0        0.0180        0.0084        0.0090        0.0032   Rock  \n",
       "1        0.0140        0.0049        0.0052        0.0044   Rock  \n",
       "2        0.0316        0.0164        0.0095        0.0078   Rock  \n",
       "3        0.0050        0.0044        0.0040        0.0117   Rock  \n",
       "4        0.0072        0.0048        0.0107        0.0094   Rock  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sonar.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PsLz6uCgf5M"
   },
   "source": [
    "Sonar is a technique that can be used to navigate, distance measure, and object detection. The sonar.csv dataset collects 208 sonar signals bounced off a metal cylinder and a roughly cylindrical rock, the signals obtained from various angles and under different conditions. There are 60 attributes(features) in the dataset. The data type of these features is float and they are in the range of 0.0 to 1.0. The metal cylinder data are labelled as Mine and the roughly cylindrical rock is labelled as Rock in the class column. The label column takes the string value either \"Mine\" or \"Rock\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47LabJgOghKE"
   },
   "source": [
    "3. Create a dataframe that holds the input features. Create a second dataframe to hold the target labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "E9vXMgHogSTv"
   },
   "outputs": [],
   "source": [
    "X_input = df.iloc[:, :-1]   #taking all the rows and all the columns except the last column\n",
    "Y_label =df['Class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYUkob7ahAeF"
   },
   "source": [
    "4. Use one-hot encoding and reshape the labels to make them neural network-compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8HHs1j9_g-Xj"
   },
   "outputs": [],
   "source": [
    "labelencoder_Y = LabelEncoder() \n",
    "Y_label = labelencoder_Y.fit_transform(Y_label)\n",
    "Y_label = Y_label.reshape([208, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRZDr78YhM5U"
   },
   "source": [
    "5. Build a multilayer neural network using Keras. You can experiment with the number of layers and neurons, but the last layer can only have one neuron with a sigmoid activation function, since this is a binary classifier. You can try different options for activation function in the input and hidden layers -- the rectilinear unit is a good option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "k_ISB4_VhIF5"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(200, input_dim=60, activation = 'relu'))\n",
    "model.add(Dense(200,  activation = 'relu'))\n",
    "model.add(Dense(100,  activation = 'relu'))\n",
    "model.add(Dense(1,  activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrt4pWFpscY7"
   },
   "source": [
    "6. Compile the model using binary cross-entropy for the loss function, accuracy as a metric, and an optimizer of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ztOg3uGKryzE"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3el3A2uZoPQN",
    "outputId": "af5134c4-a51e-47d0-8fa4-98c56230af98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 200)               12200     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,601\n",
      "Trainable params: 72,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcQrUbSvsmgC"
   },
   "source": [
    "7. Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zO6vmKZer0ub",
    "outputId": "e9e7c2fe-74f9-47d6-d5ec-d6267fbcb78f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "7/7 [==============================] - 1s 6ms/step - loss: 0.6910 - accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6499 - accuracy: 0.6731\n",
      "Epoch 3/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6010 - accuracy: 0.7212\n",
      "Epoch 4/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5442 - accuracy: 0.7452\n",
      "Epoch 5/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5091 - accuracy: 0.7740\n",
      "Epoch 6/30\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4590 - accuracy: 0.8125\n",
      "Epoch 7/30\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4169 - accuracy: 0.7933\n",
      "Epoch 8/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3849 - accuracy: 0.8365\n",
      "Epoch 9/30\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3869 - accuracy: 0.8269\n",
      "Epoch 10/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3522 - accuracy: 0.8413\n",
      "Epoch 11/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3026 - accuracy: 0.8894\n",
      "Epoch 12/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3365 - accuracy: 0.8510\n",
      "Epoch 13/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3129 - accuracy: 0.8606\n",
      "Epoch 14/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2657 - accuracy: 0.9183\n",
      "Epoch 15/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2566 - accuracy: 0.8990\n",
      "Epoch 16/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2754 - accuracy: 0.8654\n",
      "Epoch 17/30\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2359 - accuracy: 0.9183\n",
      "Epoch 18/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2684 - accuracy: 0.8750\n",
      "Epoch 19/30\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1965 - accuracy: 0.9327\n",
      "Epoch 20/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1774 - accuracy: 0.9471\n",
      "Epoch 21/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1579 - accuracy: 0.9519\n",
      "Epoch 22/30\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1707 - accuracy: 0.9135\n",
      "Epoch 23/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1626 - accuracy: 0.9663\n",
      "Epoch 24/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1346 - accuracy: 0.9519\n",
      "Epoch 25/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1009 - accuracy: 0.9808\n",
      "Epoch 26/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0888 - accuracy: 0.9808\n",
      "Epoch 27/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0832 - accuracy: 0.9856\n",
      "Epoch 28/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0856 - accuracy: 0.9856\n",
      "Epoch 29/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0593 - accuracy: 0.9856\n",
      "Epoch 30/30\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0663 - accuracy: 0.9856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4ec2e2a750>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_input, Y_label, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEo7cfEYsg1b"
   },
   "source": [
    "8. Evaluate the trained model and print out its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vQ6iKCZfr3BO",
    "outputId": "e6439b62-8d70-44f0-c450-7868a63624b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_input, Y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rAYbiceIr6ev",
    "outputId": "1020ac82-53e2-4293-8dc8-9d10db212b04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 100.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of the model is {:0.2%}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "m0PeLQlFkwGs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
